{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model to Predict Program Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('x_all.csv')\n",
    "x = x_data.to_numpy()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_scaled_sample(sample: list):\n",
    "    \"\"\"\n",
    "    Return index of sample from x_all data\n",
    "    \"\"\"\n",
    "    for i in range(len(x_scaled)):\n",
    "        found = True\n",
    "        for j in range(len(sample)):\n",
    "            if sample[j] != x_scaled[i][j]:\n",
    "                found = False\n",
    "        if found:\n",
    "            return i - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv('y_all.csv')\n",
    "y = y_data.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_parameters(model, x, y, cv, parameters):\n",
    "    grid_search = GridSearchCV(model(), parameters, n_jobs=-1)\n",
    "    grid_search.fit(x, y)\n",
    "    print(\"Best parameters combination found:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "def train_and_evaluate_model(model, x, y, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=50)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(f\"Training Score: {model.score(x_train, y_train)}\")\n",
    "    scores = cross_val_score(model, x_train, y_train)\n",
    "    print(f\"Average Cross Validation Score: {scores.mean()}, Standard Deviation: {scores.std()}\")\n",
    "    print(f\"Testing Score: {model.score(x_test, y_test)}\")\n",
    "    predictions = model.predict(x_test)\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"Predicted: {predictions[i]}, Actual: {y_test[i]}\")\n",
    "        if predictions[i] != y_test[i]:\n",
    "            print(find_x_scaled_sample(list(x_test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "activation: logistic\n",
      "alpha: 1e-05\n",
      "hidden_layer_sizes: (20, 20)\n",
      "max_iter: 2000\n",
      "solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "NN_parameters = {\n",
    "    'hidden_layer_sizes': [(5, 5), (5, 5, 5), (10,), (10, 10), (10, 10, 10), (15, 15), (20, 20), (25,), (25, 25), (50,)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 500, 1000, 2000],\n",
    "}\n",
    "NN_best_parameters = get_best_model_parameters(MLPClassifier, x_scaled, y, 5, NN_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Average Cross Validation Score: 0.7502923976608187, Standard Deviation: 0.07396216025151989\n",
      "Testing Score: 0.8260869565217391\n",
      "Predicted: 2, Actual: 4\n",
      "23\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 3, Actual: 2\n",
      "75\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 3\n",
      "50\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 4, Actual: 2\n",
      "108\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 2, Actual: 2\n"
     ]
    }
   ],
   "source": [
    "NN_best = MLPClassifier(\n",
    "    activation=NN_best_parameters['activation'],\n",
    "    alpha=NN_best_parameters['alpha'],\n",
    "    hidden_layer_sizes=NN_best_parameters['hidden_layer_sizes'],\n",
    "    solver=NN_best_parameters['solver'],\n",
    "    max_iter=NN_best_parameters['max_iter'] \n",
    ")\n",
    "\n",
    "train_and_evaluate_model(NN_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "C: 2.0\n",
      "class_weight: balanced\n",
      "max_iter: 100\n",
      "penalty: l2\n",
      "solver: liblinear\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "LR_parameters = {\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0],\n",
    "    'penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'max_iter': [100, 150, 200, 400, 800, 1600],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'warm_start': [False, True],\n",
    "}\n",
    "LR_best_paramters = get_best_model_parameters(LogisticRegression, x_scaled, y, 5, LR_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.717391304347826\n",
      "Average Cross Validation Score: 0.6076023391812866, Standard Deviation: 0.16451779785280013\n",
      "Testing Score: 0.782608695652174\n",
      "Predicted: 3, Actual: 4\n",
      "23\n",
      "Predicted: 1, Actual: 2\n",
      "15\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 3\n",
      "50\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 4, Actual: 2\n",
      "108\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 3\n",
      "97\n",
      "Predicted: 2, Actual: 2\n"
     ]
    }
   ],
   "source": [
    "LR_best = LogisticRegression(\n",
    "    C=LR_best_paramters['C'],\n",
    "    class_weight=LR_best_paramters['class_weight'],\n",
    "    max_iter=LR_best_paramters['max_iter'],\n",
    "    penalty=LR_best_paramters['penalty'],\n",
    "    solver=LR_best_paramters['solver']\n",
    ")\n",
    "\n",
    "train_and_evaluate_model(LR_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "total-operators -0.847745696099739\n",
      "distinct-operators -0.2018404531556194\n",
      "total-operands -0.9302296411278365\n",
      "distinct-operands -0.6784515601620673\n",
      "function-calls -0.7484387800922245\n",
      "loops -0.21374206955878683\n",
      "assignments 0.0009674277280126289\n",
      "max-cyclomatic-complexity -2.464998649268045\n",
      "sum-cyclomatic-complexity -1.3015946714757634\n",
      "dynamic-memory-calls -1.5511604459658814\n",
      "file-access -0.5595240159825657\n",
      "file-operation -0.5934253382217445\n",
      "file-position -0.5595240159825657\n",
      "input-output -1.053512459754973\n",
      "optimization -1.7251260581174819\n",
      "\n",
      "Class: 2\n",
      "total-operators -0.3958296427224467\n",
      "distinct-operators 0.6188731598078155\n",
      "total-operands -0.614204165067538\n",
      "distinct-operands -0.34098336111546035\n",
      "function-calls -0.6661653518553474\n",
      "loops -0.5852305769083024\n",
      "assignments 0.23037531551105525\n",
      "max-cyclomatic-complexity 0.16211635645878564\n",
      "sum-cyclomatic-complexity -1.105528546481407\n",
      "dynamic-memory-calls -0.24429035847999978\n",
      "file-access -0.36999209700846736\n",
      "file-operation -0.9501982937102644\n",
      "file-position -0.36999209700846736\n",
      "input-output -1.6400656016832031\n",
      "optimization -0.2004345960563246\n",
      "\n",
      "Class: 3\n",
      "total-operators -0.11168574158334099\n",
      "distinct-operators -0.6645130708798533\n",
      "total-operands -0.04880936501425022\n",
      "distinct-operands -0.37070444564688193\n",
      "function-calls 0.44306513290233834\n",
      "loops 0.6794052590525561\n",
      "assignments -0.15226454259118213\n",
      "max-cyclomatic-complexity -0.07979934328154875\n",
      "sum-cyclomatic-complexity 0.4949300124322466\n",
      "dynamic-memory-calls 2.044051605595335\n",
      "file-access 1.1047462584536374\n",
      "file-operation -0.31771319379669005\n",
      "file-position 1.1047462584536374\n",
      "input-output 2.1045748800458277\n",
      "optimization -0.1449770084805229\n",
      "\n",
      "Class: 4\n",
      "total-operators 1.0363366390397846\n",
      "distinct-operators 0.589620327388148\n",
      "total-operands 1.1439560311839199\n",
      "distinct-operands 1.070177058820263\n",
      "function-calls 0.4674083248699623\n",
      "loops -0.45445373960630875\n",
      "assignments -0.8225979187770437\n",
      "max-cyclomatic-complexity 0.7141818125606326\n",
      "sum-cyclomatic-complexity 1.16938368994986\n",
      "dynamic-memory-calls -2.398127498900445\n",
      "file-access -1.2755708181151502\n",
      "file-operation 0.8909525358237562\n",
      "file-position -1.2755708181151502\n",
      "input-output -0.3950712814934668\n",
      "optimization 1.1444929698079525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe weights\n",
    "for i in range(len(LR_best.coef_)):\n",
    "    print(f\"Class: {i+1}\")\n",
    "    weights = list(LR_best.coef_[i])\n",
    "    for j in range(len(x_data.columns)):\n",
    "        print(x_data.columns[j], weights[j])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
