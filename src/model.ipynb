{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model to Predict Program Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('x_all.csv')\n",
    "x = x_data.to_numpy()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_scaled_sample(sample: list):\n",
    "    \"\"\"\n",
    "    Return index of sample from x_all data\n",
    "    \"\"\"\n",
    "    for i in range(len(x_scaled)):\n",
    "        found = True\n",
    "        for j in range(len(sample)):\n",
    "            if sample[j] != x_scaled[i][j]:\n",
    "                found = False\n",
    "        if found:\n",
    "            return i - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv('y_all.csv')\n",
    "y = y_data.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_parameters(model, x, y, cv, parameters):\n",
    "    grid_search = GridSearchCV(model(), parameters, n_jobs=-1)\n",
    "    grid_search.fit(x, y)\n",
    "    print(\"Best parameters combination found:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "def train_and_evaluate_model(model, x, y, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=50)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(f\"Training Score: {model.score(x_train, y_train)}\")\n",
    "    scores = cross_val_score(model, x_train, y_train)\n",
    "    print(f\"Average Cross Validation Score: {scores.mean()}, Standard Deviation: {scores.std()}\")\n",
    "    print(f\"Testing Score: {model.score(x_test, y_test)}\")\n",
    "    predictions = model.predict(x_test)\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"Predicted: {predictions[i]}, Actual: {y_test[i]}\")\n",
    "        if predictions[i] != y_test[i]:\n",
    "            print(find_x_scaled_sample(list(x_test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "activation: logistic\n",
      "alpha: 0.001\n",
      "hidden_layer_sizes: (25, 25)\n",
      "max_iter: 2000\n",
      "solver: adam\n"
     ]
    }
   ],
   "source": [
    "NN_parameters = {\n",
    "    'hidden_layer_sizes': [(5,), (5, 5), (10,), (10, 10), (25,), (25, 25), (50,), (100,)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 500, 1000, 2000],\n",
    "}\n",
    "NN_best_parameters = get_best_model_parameters(MLPClassifier, x_scaled, y, 5, NN_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Average Cross Validation Score: 0.7849999999999999, Standard Deviation: 0.09300537618869138\n",
      "Testing Score: 0.8\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 1\n",
      "50\n",
      "Predicted: 3, Actual: 2\n",
      "48\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 3, Actual: 4\n",
      "23\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 1, Actual: 2\n",
      "93\n",
      "Predicted: 3, Actual: 3\n"
     ]
    }
   ],
   "source": [
    "NN_best = MLPClassifier(\n",
    "    activation=NN_best_parameters['activation'],\n",
    "    alpha=NN_best_parameters['alpha'],\n",
    "    hidden_layer_sizes=NN_best_parameters['hidden_layer_sizes'],\n",
    "    solver=NN_best_parameters['solver'],\n",
    "    max_iter=NN_best_parameters['max_iter'] \n",
    ")\n",
    "\n",
    "train_and_evaluate_model(NN_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "C: 3.0\n",
      "class_weight: balanced\n",
      "max_iter: 100\n",
      "penalty: l2\n",
      "solver: liblinear\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "LR_parameters = {\n",
    "    'C': [0.01, 0.1, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'max_iter': [100, 150, 200, 400, 800, 1600],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'warm_start': [False, True],\n",
    "}\n",
    "LR_best_paramters = get_best_model_parameters(LogisticRegression, x_scaled, y, 5, LR_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7974683544303798\n",
      "Average Cross Validation Score: 0.6966666666666667, Standard Deviation: 0.04357305487467123\n",
      "Testing Score: 0.7\n",
      "Predicted: 4, Actual: 2\n",
      "83\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 1\n",
      "50\n",
      "Predicted: 3, Actual: 2\n",
      "48\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 2, Actual: 3\n",
      "1\n",
      "Predicted: 3, Actual: 4\n",
      "23\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 1, Actual: 2\n",
      "93\n",
      "Predicted: 3, Actual: 3\n"
     ]
    }
   ],
   "source": [
    "LR_best = LogisticRegression(\n",
    "    C=LR_best_paramters['C'],\n",
    "    class_weight=LR_best_paramters['class_weight'],\n",
    "    max_iter=LR_best_paramters['max_iter'],\n",
    "    penalty=LR_best_paramters['penalty'],\n",
    "    solver=LR_best_paramters['solver']\n",
    ")\n",
    "\n",
    "train_and_evaluate_model(LR_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "total-operators -0.65015400612366\n",
      "distinct-operators 0.34487115394580625\n",
      "total-operands -0.8486804580405449\n",
      "distinct-operands -0.6503561006441376\n",
      "function-calls -0.3547253698783957\n",
      "loops -0.7102545809554834\n",
      "assignments 0.13244209165684567\n",
      "max-cyclomatic-complexity -3.8809481003874615\n",
      "sum-cyclomatic-complexity -1.7559071940403186\n",
      "dynamic-memory-calls -1.837204061900299\n",
      "file-access -0.7036209577455077\n",
      "file-operation -0.72981912931579\n",
      "file-position -0.7036209577455077\n",
      "input-output -1.4802148381687912\n",
      "optimization -2.0018874979095616\n",
      "\n",
      "Class: 2\n",
      "total-operators -0.04758663848357379\n",
      "distinct-operators 0.3357394221740785\n",
      "total-operands -0.21973769828304182\n",
      "distinct-operands 0.16210244215277245\n",
      "function-calls -0.8514444153000937\n",
      "loops -1.3310715121452534\n",
      "assignments 0.46833709406302587\n",
      "max-cyclomatic-complexity 0.5954147592655599\n",
      "sum-cyclomatic-complexity -0.9303897751079943\n",
      "dynamic-memory-calls -0.0298472648230249\n",
      "file-access -0.25692616826182807\n",
      "file-operation -1.6047826158685117\n",
      "file-position -0.25692616826182807\n",
      "input-output -2.264678504430578\n",
      "optimization 0.09834460708024889\n",
      "\n",
      "Class: 3\n",
      "total-operators -0.37350820733724505\n",
      "distinct-operators -0.5853918151896127\n",
      "total-operands -0.24285131853235292\n",
      "distinct-operands -0.7210321657403409\n",
      "function-calls 0.5375305450252678\n",
      "loops 1.5258559740961235\n",
      "assignments -0.9981147681504855\n",
      "max-cyclomatic-complexity -0.2982524739191052\n",
      "sum-cyclomatic-complexity 0.7904058179304946\n",
      "dynamic-memory-calls 1.8456182780581596\n",
      "file-access 1.2945139650807662\n",
      "file-operation -0.9301647196976707\n",
      "file-position 1.2945139650807662\n",
      "input-output 2.8054447572348584\n",
      "optimization -0.10178871131355881\n",
      "\n",
      "Class: 4\n",
      "total-operators 0.868330503978085\n",
      "distinct-operators 0.9608754546037485\n",
      "total-operands 0.825894049229553\n",
      "distinct-operands 0.745290332707494\n",
      "function-calls 0.26068493686518474\n",
      "loops -0.29386918637144704\n",
      "assignments -0.4525844002491954\n",
      "max-cyclomatic-complexity 1.1827861471981098\n",
      "sum-cyclomatic-complexity 0.800721392713381\n",
      "dynamic-memory-calls -2.826188783050196\n",
      "file-access -1.6309268933150125\n",
      "file-operation 1.8663681472574152\n",
      "file-position -1.6309268933150125\n",
      "input-output -0.26650472196280156\n",
      "optimization 0.892098172310268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe weights\n",
    "for i in range(len(LR_best.coef_)):\n",
    "    print(f\"Class: {i+1}\")\n",
    "    weights = list(LR_best.coef_[i])\n",
    "    for j in range(len(x_data.columns)):\n",
    "        print(x_data.columns[j], weights[j])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
