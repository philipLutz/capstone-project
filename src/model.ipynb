{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model to Predict Program Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('x_all.csv')\n",
    "x = x_data.to_numpy()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_scaled_sample(sample: list):\n",
    "    \"\"\"\n",
    "    Return index of sample from x_all data\n",
    "    \"\"\"\n",
    "    for i in range(len(x_scaled)):\n",
    "        found = True\n",
    "        for j in range(len(sample)):\n",
    "            if sample[j] != x_scaled[i][j]:\n",
    "                found = False\n",
    "        if found:\n",
    "            return i - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv('y_all.csv')\n",
    "y = y_data.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_parameters(model, x, y, cv, parameters):\n",
    "    grid_search = GridSearchCV(model(), parameters, n_jobs=-1)\n",
    "    grid_search.fit(x, y)\n",
    "    print(\"Best parameters combination found:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "def train_and_evaluate_model(model, x, y, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=50)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(f\"Training Score: {model.score(x_train, y_train)}\")\n",
    "    scores = cross_val_score(model, x_train, y_train)\n",
    "    print(f\"Average Cross Validation Score: {scores.mean()}, Standard Deviation: {scores.std()}\")\n",
    "    print(f\"Testing Score: {model.score(x_test, y_test)}\")\n",
    "    predictions = model.predict(x_test)\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"Predicted: {predictions[i]}, Actual: {y_test[i]}\")\n",
    "        if predictions[i] != y_test[i]:\n",
    "            print(find_x_scaled_sample(list(x_test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "activation: logistic\n",
      "alpha: 0.0001\n",
      "hidden_layer_sizes: (25, 25)\n",
      "max_iter: 500\n",
      "solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "NN_parameters = {\n",
    "    'hidden_layer_sizes': [(5,), (5, 5), (10,), (10, 10), (25,), (25, 25), (50,), (100,)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 500, 1000, 2000],\n",
    "}\n",
    "NN_best_parameters = get_best_model_parameters(MLPClassifier, x_scaled, y, 5, NN_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Average Cross Validation Score: 0.8066176470588236, Standard Deviation: 0.10075407725270963\n",
      "Testing Score: 0.7619047619047619\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 2\n",
      "97\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 3\n",
      "40\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 3, Actual: 4\n",
      "23\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 3\n",
      "73\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 2\n",
      "38\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n"
     ]
    }
   ],
   "source": [
    "NN_best = MLPClassifier(\n",
    "    activation=NN_best_parameters['activation'],\n",
    "    alpha=NN_best_parameters['alpha'],\n",
    "    hidden_layer_sizes=NN_best_parameters['hidden_layer_sizes'],\n",
    "    solver=NN_best_parameters['solver'],\n",
    "    max_iter=NN_best_parameters['max_iter'] \n",
    ")\n",
    "\n",
    "train_and_evaluate_model(NN_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "C: 1.0\n",
      "class_weight: balanced\n",
      "max_iter: 200\n",
      "penalty: l1\n",
      "solver: saga\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "LR_parameters = {\n",
    "    'C': [0.01, 0.1, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'max_iter': [100, 150, 200, 400, 800, 1600],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'warm_start': [False, True],\n",
    "}\n",
    "LR_best_paramters = get_best_model_parameters(LogisticRegression, x_scaled, y, 5, LR_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7073170731707317\n",
      "Average Cross Validation Score: 0.6713235294117647, Standard Deviation: 0.07127424009442726\n",
      "Testing Score: 0.5714285714285714\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 1, Actual: 2\n",
      "15\n",
      "Predicted: 1, Actual: 2\n",
      "97\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 1, Actual: 3\n",
      "40\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 3, Actual: 4\n",
      "23\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 3, Actual: 3\n",
      "Predicted: 1, Actual: 2\n",
      "54\n",
      "Predicted: 4, Actual: 3\n",
      "73\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 4, Actual: 4\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 1, Actual: 2\n",
      "38\n",
      "Predicted: 2, Actual: 3\n",
      "59\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 2\n",
      "Predicted: 2, Actual: 3\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "LR_best = LogisticRegression(\n",
    "    C=LR_best_paramters['C'],\n",
    "    class_weight=LR_best_paramters['class_weight'],\n",
    "    max_iter=LR_best_paramters['max_iter'],\n",
    "    penalty=LR_best_paramters['penalty'],\n",
    "    solver=LR_best_paramters['solver']\n",
    ")\n",
    "\n",
    "train_and_evaluate_model(LR_best, x_scaled, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "total-operators 0.0\n",
      "distinct-operators -0.6190057903936915\n",
      "total-operands 0.0\n",
      "distinct-operands 0.0\n",
      "function-calls 0.0\n",
      "loops 0.0\n",
      "assignments 0.0\n",
      "max-cyclomatic-complexity -5.044632079375413\n",
      "sum-cyclomatic-complexity 0.0\n",
      "dynamic-memory-calls 0.0\n",
      "file-access 0.0\n",
      "file-operation 0.0\n",
      "file-position 0.0\n",
      "input-output 0.0\n",
      "optimization -1.947868946924398\n",
      "\n",
      "Class: 2\n",
      "total-operators 0.0\n",
      "distinct-operators 0.0\n",
      "total-operands 0.0\n",
      "distinct-operands 0.0\n",
      "function-calls 0.0\n",
      "loops 0.0\n",
      "assignments 0.0\n",
      "max-cyclomatic-complexity 0.0\n",
      "sum-cyclomatic-complexity 0.0\n",
      "dynamic-memory-calls 0.0\n",
      "file-access 0.0\n",
      "file-operation 0.0\n",
      "file-position 0.0\n",
      "input-output 0.0\n",
      "optimization 0.0\n",
      "\n",
      "Class: 3\n",
      "total-operators 0.0\n",
      "distinct-operators 0.0\n",
      "total-operands 0.0\n",
      "distinct-operands 0.0\n",
      "function-calls 0.0\n",
      "loops 0.0\n",
      "assignments 0.0\n",
      "max-cyclomatic-complexity 0.0\n",
      "sum-cyclomatic-complexity 0.0\n",
      "dynamic-memory-calls 1.8684305853360388\n",
      "file-access 0.0\n",
      "file-operation 0.0\n",
      "file-position 0.0\n",
      "input-output 5.75138502733829\n",
      "optimization 0.0\n",
      "\n",
      "Class: 4\n",
      "total-operators 0.0\n",
      "distinct-operators 3.1677803971501968\n",
      "total-operands 0.0\n",
      "distinct-operands 0.0\n",
      "function-calls 0.0\n",
      "loops 0.0\n",
      "assignments 0.0\n",
      "max-cyclomatic-complexity 2.6384174796816398\n",
      "sum-cyclomatic-complexity 0.0\n",
      "dynamic-memory-calls -1.1636828608212464\n",
      "file-access 0.0\n",
      "file-operation 1.2369068789491433\n",
      "file-position 0.0\n",
      "input-output 0.0\n",
      "optimization 1.0587093842131796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe weights\n",
    "for i in range(len(LR_best.coef_)):\n",
    "    print(f\"Class: {i+1}\")\n",
    "    weights = list(LR_best.coef_[i])\n",
    "    for j in range(len(x_data.columns)):\n",
    "        print(x_data.columns[j], weights[j])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
